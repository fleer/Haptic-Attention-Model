import numpy as np
import tensorflow as tf
from collections import defaultdict
import logging
import time
import os
import json
import h5py

from learner import Learner

class Experiment():
    """
    Main class, controlling the experiment
    """

    # Create dict for the results
    results = defaultdict(list)


    def __init__(self,PARAMETERS):
        """
        The main function of the class that controlls the whole experiment
        :param PARAMETERS: The parameter configuration that is used for learning
        """

        # create logger and set level to info
        self.logger = logging.getLogger("Experiment")
        self.logger.setLevel(level=logging.INFO)
        ch = logging.StreamHandler()
        ch.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s:%(name)s: >>> %(message)s')
        ch.setFormatter(formatter)
        self.logger.addHandler(ch)

        # Logging interval (number of training steps)
        log_interval = 50

        # Interval for performance evaluation(number of training steps)
        log_performance_interval = 200

        # First Glance is always random
        if PARAMETERS.GLANCES == 1:
            PARAMETERS.RANDOM_LOCS = True
        #   ================
        #   Reading the parameters
        #   ================

        tf.compat.v1.reset_default_graph()

        with tf.compat.v1.Session() as sess:


            learner = Learner(PARAMETERS=PARAMETERS,sess=sess)
            saver = tf.compat.v1.train.Saver(max_to_keep=1)

            # Create h5df file for saving locations, generated by the policy
            if PARAMETERS.SAVE_SENSOR_POLICY:
                file_path = os.path.join(PARAMETERS.RESULTS_PATH, "location_data.hdf5")
                if not os.path.exists(PARAMETERS.RESULTS_PATH):
                    os.makedirs(PARAMETERS.RESULTS_PATH)


            # Load Model if desired
            if PARAMETERS.LOAD_MODEL == True:
                print ('Loading Model...')
                ckpt = tf.compat.v1.train.get_checkpoint_state(PARAMETERS.MODEL_FILE_PATH)
                saver.restore(sess, ckpt.model_checkpoint_path)
            else:
                sess.run(tf.compat.v1.global_variables_initializer())

            # Initialize Tensorboard Summary
            self.summary_writer = tf.compat.v1.summary.FileWriter(PARAMETERS.RESULTS_PATH + "summary", sess.graph)

            #   ================
            #   Train
            #   ================
            early_stopping_accuracy = 0.
            patience_steps = 0
            lr = PARAMETERS.LEARNING_RATE
            a_loss = []
            l_loss = []
            s_loss = []
            b_loss = []
            reward = []
            glance_rewards = defaultdict(list)
            accumulated_glance_rewards = defaultdict(list)


            #   ================
            #   The Main Loop!
            #   ================
            for steps in range(PARAMETERS.MAX_STEPS+1):
                start_time = time.time()

                #   ================
                #   Performance Check
                #   ================
                if False:
                #if steps % log_performance_interval == 0:
                    performance_accuracy, performance_accuracy_std, \
                    performance_glance_accuracy, performance_accumulated_glance_accuracy, performance_locations,\
                    performance_locations_mu_x_a, performance_locations_mu_std_x, \
                    performance_locations_mu_std_a = learner.evaluate()
                    # Print out Infos
                    self.logger.info("Performance run: >>> Step={:d} Train-Accuracy: {:.4f}, Learning Rate: {:.6f}".format(steps, performance_accuracy, lr))

                    # Write tf.compat.v1 Summary
                    summary = tf.compat.v1.Summary()
                    summary.value.add(tag='Performance/Accuracy', simple_value=float(np.mean(performance_accuracy)))
                    # TODO: Check Glance Accuracy
                    for r in range(PARAMETERS.GLANCES):
                        summary.value.add(tag='Performance/Accuracy Swipe_' + str(r+1), simple_value=float(np.mean(performance_glance_accuracy[r])))
                        summary.value.add(tag='Performance/Accumulated Accuracy Swipe_' + str(r+1), simple_value=float(np.mean(performance_accumulated_glance_accuracy[r])))
                    self.summary_writer.add_summary(summary, steps)
                    self.summary_writer.flush()

                    # Write the used locations and orientation of the sensor into location_data.hdf5
                    # --> Only the data of the last glance is used
                    # And create some heatmaps for visualization
                    if PARAMETERS.SAVE_SENSOR_POLICY and not PARAMETERS.RANDOM_LOCS:
                        policy_save = h5py.File(file_path, 'a')
                        for o in range(PARAMETERS.OBJECT_NUM):
                            # Save the data
                            policy_save.create_dataset("object_" + str(o) + "/sampled_locations/" + str(steps), data=performance_locations[o])
                            policy_save.create_dataset("object_" + str(o) + "/mean_locations/" + str(steps), data=performance_locations_mu_x_a[o])
                            policy_save.create_dataset("object_" + str(o) + "/mean_std_posistion_locations/" + str(steps), data=performance_locations_mu_std_x[o])
                            policy_save.create_dataset("object_" + str(o) + "/mean_std_angle_locations/" + str(steps), data=performance_locations_mu_std_a[o])
                        policy_save.close()
                    if PARAMETERS.HEATMAPS:
                        for o in range(PARAMETERS.OBJECT_NUM):
                            # Create Heat-Maps with Matpoltlib
                            self.save_location(PARAMETERS.RESULTS_PATH + "Percentile/", "object_" +
                                                   str(o) + "_" + str(steps),performance_locations[o], "percentile")
                            self.save_location_mu(PARAMETERS.RESULTS_PATH + "Percentile/", "object_" +
                                                      str(o) + "_mu" + str(steps),performance_locations_mu_x_a[o], "percentile")
                            self.save_location_mu_std(PARAMETERS.RESULTS_PATH + "Percentile/", "object_" +
                                               str(o) + "_mu_std_pos" + str(steps),performance_locations_mu_std_x[o], "percentile")
                            self.save_location_mu_std(PARAMETERS.RESULTS_PATH + "Percentile/", "object_" +
                                                      str(o) + "_mu_std_angle" + str(steps),performance_locations_mu_std_a[o], "percentile","angle")
                            self.save_location(PARAMETERS.RESULTS_PATH + "Percent/", "object_" +
                                               str(o) + "_" + str(steps),performance_locations[o],"percent")
                            self.save_location_mu(PARAMETERS.RESULTS_PATH + "Percent/", "object_" +
                                                  str(o) + "_mu" + str(steps),performance_locations_mu_x_a[o],"percent")
                            self.save_location_mu_std(PARAMETERS.RESULTS_PATH + "Percent/", "object_" +
                                                      str(o) + "_mu_std_pos" + str(steps),performance_locations_mu_std_x[o],"percent")
                            self.save_location_mu_std(PARAMETERS.RESULTS_PATH + "Percent/", "object_" +
                                                      str(o) + "_mu_std_angle" + str(steps),performance_locations_mu_std_a[o],"percent","angle")
                            self.save_location(PARAMETERS.RESULTS_PATH + "Absolute/", "object_" +
                                               str(o) + "_" + str(steps),performance_locations[o], "absolute")
                            self.save_location_mu(PARAMETERS.RESULTS_PATH + "Absolute/", "object_" +
                                                  str(o) + "_mu" + str(steps),performance_locations_mu_x_a[o], "absolute")
                            self.save_location_mu_std(PARAMETERS.RESULTS_PATH + "Absolute/", "object_" +
                                                      str(o) + "_mu_std_pos" + str(steps),performance_locations_mu_std_x[o], "absolute")
                            self.save_location_mu_std(PARAMETERS.RESULTS_PATH + "Absolute/", "object_" +
                                                      str(o) + "_mu_std_angle" + str(steps),performance_locations_mu_std_a[o], "absolute","angle")

                    # Save Model
                    saver.save(sess, save_path=PARAMETERS.MODEL_FILE_PATH, global_step=steps)

                    # Save to results file
                    self.results['learning_steps'].append(steps)
                    self.results['accuracy'].append(float(performance_accuracy))
                    self.results['accuracy_std'].append(float(performance_accuracy_std))
                    for r in range(PARAMETERS.GLANCES):
                        self.results['accuracy_glance_' + str(r+1)].append(float(np.mean(performance_glance_accuracy[r])))
                        self.results['accumulated_accuracy_glance_' + str(r+1)].append(float(np.mean(performance_accumulated_glance_accuracy[r])))

                    # Early Stopping
                    if PARAMETERS.EARLY_STOPPING:
                        if early_stopping_accuracy < performance_accuracy:
                            early_stopping_accuracy = performance_accuracy
                            patience_steps = 0
                        else:
                            patience_steps += 1

                   # Early Stopping
                    if patience_steps > PARAMETERS.PATIENCE:
                        saver.save(sess, './Model/best_model-' + str(steps) + '.cptk')
                        logging.info("Early Stopping at Epoch={:d}! Test Accuracy "
                                     "is not increasing. The best Newtork will be saved!".format(steps))
                        break

                # Train the model
                reward_fetched, prediction_labels_fetched, cost_a_fetched, cost_l_fetched, cost_s_fetched, cost_b_fetched, \
                reward_list, accumulated_reward_list = learner.train()

                # Save the computed loss for the different parts

                # Full Loss
                a_loss.append(cost_a_fetched)
                # REINFORCE Loss Mean
                l_loss.append(cost_l_fetched)
                # REINFORCE Loss Std
                s_loss.append(cost_s_fetched)
                # Baseline loss
                b_loss.append(cost_b_fetched)
                # Achieved reward
                reward.append(np.mean(reward_fetched))

                # Achieved reward if classified after the current glance
                for r in range(PARAMETERS.GLANCES):
                    glance_rewards[r].append(np.mean(reward_list[r], axis=-1))
                    accumulated_glance_rewards[r].append(accumulated_reward_list[r])

                # Print out intermediate Infos
                if steps % log_interval == 0:
                    self.logger.info("Step={:d}: >>> examples/s: {:.2f}, Accumulated-Loss: {:.4f}, Location-Mean Loss: {:.4f},"
                                 " Location-Stddev Loss: {:.4f}, Baseline-Loss: {:.4f} "
                                 "Learning Rate: {:.6f}, Train-Accuracy: {:.4f}".format(steps,
                                float(PARAMETERS.BATCH_SIZE)/float(time.time()-start_time), np.mean(a_loss),
                                np.mean(l_loss), np.mean(s_loss), np.mean(b_loss), lr, np.mean(reward)))

                    # Gather information for Tensorboard
                    summary = tf.compat.v1.Summary()
                    summary.value.add(tag='Losses/Accumulated Loss', simple_value=float(np.mean(a_loss)))
                    summary.value.add(tag='Losses/Location: Mean Loss', simple_value=float(np.mean(l_loss)))
                    summary.value.add(tag='Losses/Location: Stddev Loss', simple_value=float(np.mean(s_loss)))
                    summary.value.add(tag='Losses/Baseline Loss', simple_value=float(np.mean(b_loss)))
                    summary.value.add(tag='Accuracy/Train', simple_value=float(np.mean(reward)))
                    for r in range(PARAMETERS.GLANCES):
                        summary.value.add(tag='Accuracy/Swipe_' + str(r+1), simple_value=float(np.mean(glance_rewards[r])))
                        summary.value.add(tag='Accuracy/Accumulated Swipe_' + str(r+1), simple_value=float(np.mean(accumulated_glance_rewards[r])))
                    self.summary_writer.add_summary(summary, steps)

                    self.summary_writer.flush()

                    a_loss = []
                    l_loss = []
                    s_loss = []
                    b_loss = []
                    reward = []
                    del(glance_rewards)
                    del(accumulated_glance_rewards)
                    glance_rewards = defaultdict(list)
                    accumulated_glance_rewards = defaultdict(list)


                lr = learner.learning_rate_decay()

            # Save the results to results.json
            self.save(PARAMETERS.RESULTS_PATH, 'results.json')
            self.results.clear()

    def save_location_mu_std(self, path, filename, data, p="percentile", label="pos"):
        """
        Function for creating a heatmap that visualizes the distribution of the mean and std
        generated for positioning the sensor during the performance runs
        :param path: Path for output file
        :param filename: Name of the output file
        :param data: used data for generating the plot
        :param p: Use Percent or Percentile
        :param label: Plot Position or Orientation
        :return:
        """
        import math
        from scipy import stats
        import matplotlib as mpl
        mpl.use('Agg')
        import matplotlib.pyplot as plt
        from mpl_toolkits.axes_grid1 import make_axes_locatable
        plt.rc('text', usetex=True)
        fontsize = 12
        plt.rc('font', family='serif')

        results_fn = os.path.join(path, filename)
        if not os.path.exists(path):
            os.makedirs(path)
        matrix = np.zeros((20,20))
        count = 0
        max = 0
        for d in data:
            # Save 20x20 matrix for better visualization
            index_mu = int(np.minimum((1.+d[0]) * 10.,19))
            index_std = int(np.minimum(d[1] * 20.,19))
            count += 1
            matrix[index_std][index_mu] = matrix[index_std][index_mu] + 1
            if max < matrix[index_std][index_mu]:
                max = matrix[index_std][index_mu]
        matrix = np.asarray(matrix)
        if p == "percentile":
            # In order to have comparable heatmaps for each object,
            # the percentile of the visits relative to the list of all visits
            # is computed for each entry of the matrix
            # Everything is then mapped between [0,1]
            matrix_map = []
            max = 100
            for m in matrix:
                matrix_map.append([stats.percentileofscore(matrix.flatten(), a, 'rank') for a in m])

            matrix_map = np.asarray(matrix_map)
            np.testing.assert_array_equal(matrix.shape, matrix_map.shape, 'Arrays have different shape!')
        elif p == "percent":
            matrix_map = matrix * (100./float(count))
            max = int(max*(100./float(count)))
            max = int(math.ceil(max/10.0))*10
        elif p == "absolute":
            # Take the largest number of visits of one cell
            # as the maximal value for the heat-map
            matrix_map = matrix
        else:
            import sys
            print("Wrong measure option: {}".format(p))
            sys.exit(0)
        fig = plt.figure(filename)
        ax = fig.add_subplot(111)
        im = ax.imshow(matrix_map, cmap='coolwarm', vmin=0, vmax=max, interpolation='nearest')
        t = [0,5,9.5,15,19]
        t_mu = [-1,-0.5,0,0.5,1]
        t_std = [0,0.25,0.5,0.75,1]
        if label == "angle":
            plt.xticks(t, [r"$-\frac{\pi}{2}$", r"$-\frac{\pi}{4}$", r"$0$", r"$\frac{\pi}{4}$", r"$\frac{\pi}{2}$"])
            plt.xlabel(r"Mean $\mu_\varphi$", fontsize=fontsize)
            plt.ylabel(r"Standard Deviation $\sigma_\varphi$", fontsize=fontsize)
        else:
            plt.xticks(t, t_mu)
            plt.xlabel(r"Mean $\mu_x$", fontsize=fontsize)
            plt.ylabel(r"Standard Deviation $\sigma_x$", fontsize=fontsize)

        plt.yticks(t, t_std)
        plt.tight_layout()
        # create an axes on the right side of ax. The width of cax will be 5%
        # of ax and the padding between cax and ax will be fixed at 0.05 inch.
        divider = make_axes_locatable(ax)
        cax = divider.append_axes("right", size="5%", pad=0.05)
        plt.colorbar(im, cax=cax)
        plt.savefig(results_fn + ".pdf")
        fig.clear()
        plt.clf()
        fig = None

    def save_location_mu(self, path, filename, data, p = "percentile"):
        """
        Function for creating a heatmap that visualizes the distribution of the means
        of the generated position and orientation the sensor uses during the performance run
        :param path: Path for output file
        :param filename: Name of the output file
        :param data: used data for generating the plot
        :param p: Use Percent or Percentile
        :return:
        """
        from scipy import stats
        import math
        import matplotlib as mpl
        mpl.use('Agg')
        import matplotlib.pyplot as plt
        from mpl_toolkits.axes_grid1 import make_axes_locatable
        plt.rc('text', usetex=True)
        fontsize = 12
        plt.rc('font', family='serif')

        results_fn = os.path.join(path, filename)
        if not os.path.exists(path):
            os.makedirs(path)
        matrix = np.zeros((20,20))
        count = 0
        max = 0
        for d in data:
            # Save 20x20 matrix for better visualization
            index_l = int(np.minimum((1.+d[0]) * 10.,19))
            index_e = int(np.minimum((1.+d[1]) * 10.,19))
            count += 1
            matrix[index_e][index_l] = matrix[index_e][index_l] + 1
            if max < matrix[index_e][index_l]:
                max = matrix[index_e][index_l]
        matrix = np.asarray(matrix)

        if p == "percentile":
            # In order to have comparable heatmaps for each object,
            # the percentile of the visits relative to the list of all visits
            # is computed for each entry of the matrix
            # Everything is then mapped between [0,1]
            matrix_map = []
            max = 100
            for m in matrix:
                matrix_map.append([stats.percentileofscore(matrix.flatten(), a, 'rank') for a in m])

            matrix_map = np.asarray(matrix_map)
            np.testing.assert_array_equal(matrix.shape, matrix_map.shape, 'Arrays have different shape!')
        elif p == "percent":
            matrix_map = matrix * (100./float(count))
            max = int(max*(100./float(count)))
            max = int(math.ceil(max/10.0))*10
        elif p == "absolute":
            # Take the largest number of visits of one cell
            # as the maximal value for the heat-map
            matrix_map = matrix
        else:
            import sys
            print("Wrong measure option: {}".format(p))
            sys.exit(0)
        fig = plt.figure(filename)
        ax = fig.add_subplot(111)
        im = ax.imshow(matrix_map, cmap='coolwarm', vmin=0, vmax=max, interpolation='nearest')
        tx = [0,5,9.5,15,19]
        ty = [-1,-0.5,0,0.5,1]
        plt.xticks(tx, ty)
        plt.yticks(tx, [r"$-\frac{\pi}{2}$", r"$-\frac{\pi}{4}$", r"$0$", r"$\frac{\pi}{4}$", r"$\frac{\pi}{2}$"])
        plt.xlabel(r"Position $\mu_x$", fontsize=fontsize)
        plt.ylabel(r"Angle $\mu_\varphi$", fontsize=fontsize)
        plt.tight_layout()
        # create an axes on the right side of ax. The width of cax will be 5%
        # of ax and the padding between cax and ax will be fixed at 0.05 inch.
        divider = make_axes_locatable(ax)
        cax = divider.append_axes("right", size="5%", pad=0.05)
        plt.colorbar(im, cax=cax)
        plt.savefig(results_fn + ".pdf")
        fig.clear()
        plt.clf()
        fig = None

    def save_location(self, path, filename, data, p="percentile"):
        """
        Function for creating a heatmap that visualizes the distribution of the sampled location
        of the generated position and orientation the sensor uses during the performance run
        :param path: Path for output file
        :param filename: Name of the output file
        :param data: used data for generating the plot
        :param p: Use Percent or Percentile
        :return:
        """
        from scipy import stats
        import math
        import matplotlib as mpl
        mpl.use('Agg')
        import matplotlib.pyplot as plt
        from mpl_toolkits.axes_grid1 import make_axes_locatable
        plt.rc('text', usetex=True)
        fontsize = 12
        plt.rc('font', family='serif')

        results_fn = os.path.join(path, filename)
        if not os.path.exists(path):
            os.makedirs(path)
        matrix = np.zeros((20,20))
        count = 0
        max = 0
        # Save 20x20 matrix for better visualization
        for d in data:
            index_l = int(np.minimum((1.+d[0]) * 10.,19))
            index_e = int(np.minimum((1.+d[1]) * 10.,19))
            count += 1
            matrix[index_e][index_l] = matrix[index_e][index_l] + 1
            if max < matrix[index_e][index_l]:
                max = matrix[index_e][index_l]
        matrix = np.asarray(matrix)

        if p == "percentile":
            # In order to have comparable heatmaps for each object,
            # the percentile of the visits relative to the list of all visits
            # is computed for each entry of the matrix
            # Everything is then mapped between [0,1]
            matrix_map = []
            max = 100
            for m in matrix:
                matrix_map.append([stats.percentileofscore(matrix.flatten(), a, 'rank') for a in m])

            matrix_map = np.asarray(matrix_map)
            np.testing.assert_array_equal(matrix.shape, matrix_map.shape, 'Arrays have different shape!')
        elif p == "percent":
            matrix_map = matrix * (100./float(count))
            max = int(max*(100./float(count)))
            max = int(math.ceil(max/10.0))*10
            if max < 1:
                max = 1
            elif max < 2:
                max = 2
            elif max < 3:
                max = 3
            elif max < 4:
                max = 4
            elif max < 5.:
                max = 5
            elif max < 10.:
                max = 10
        elif p == "absolute":
            matrix_map = matrix
        else:
            import sys
            print("Wrong measure option: {}".format(p))
            sys.exit(0)
        fig = plt.figure(filename)
        ax = fig.add_subplot(111)
        im = ax.imshow(matrix_map, cmap='coolwarm', vmin=0, vmax=max, interpolation='nearest')
        tx = [0,5,9.5,15,19]
        ty = [-1,-0.5,0,0.5,1]
        plt.xticks(tx, ty)
        plt.yticks(tx, [r"$-\frac{\pi}{2}$", r"$-\frac{\pi}{4}$", r"$0$", r"$\frac{\pi}{4}$", r"$\frac{\pi}{2}$"])
        plt.xlabel(r"Position $x$", fontsize=fontsize)
        plt.ylabel(r"Angle $\varphi$", fontsize=fontsize)
        plt.tight_layout()
        # create an axes on the right side of ax. The width of cax will be 5%
        # of ax and the padding between cax and ax will be fixed at 0.05 inch.
        divider = make_axes_locatable(ax)
        cax = divider.append_axes("right", size="5%", pad=0.05)
        plt.colorbar(im, cax=cax)
        plt.savefig(results_fn + ".pdf")
        fig.clear()
        plt.clf()
        fig = None


    def save(self, path, filename):
        """
        Saves the experimental results to ``results.json`` file
        :param path: path to results file
        :param filename: filename of results file
        """
        results_fn = os.path.join(path, filename)
        if not os.path.exists(path):
            os.makedirs(path)
        with open(results_fn, "w") as f:
            json.dump(self.results, f, indent=4, sort_keys=True)
        f.close()
