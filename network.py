import os

import numpy as np
import tensorflow as tf

class AttentionControl(tf.keras.layers.Layer):
    """
    Loop function of recurrent attention network
    :return: next glance
    """
    def __init__(self, PARAMETERS):
        super(AttentionControl, self).__init__()

        # Size of Hidden state
        self.hs_size = PARAMETERS.HIDDEN_STATE
        self.hn_size = PARAMETERS.HAPTIC_NET

        self.eval_location_list = []
        self.location_list = []
        self.location_mean_list = []
        self.location_stddev_list = []
        self.glances_list = []

        # Initialize weights
        self.h_location_std_out_x = tf.keras.layers.Dense(1,
                activation='tanh',
                kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1))
        self.h_location_out_x = tf.keras.layers.Dense(1,
                activation='tanh',
                kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1))
        self.h_location_std_out_a = tf.keras.layers.Dense(1,
                activation='sigmoid',
                kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1))
        self.h_location_out_a = tf.keras.layers.Dense(1,
                activation='sigmoid',
                kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1))

        # glance Net
        self.h_glance_layer = tf.keras.layers.Dense(hg_size, activation='relu',
                kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1))
        self.h_location_layer = tf.keras.layers.Dense(hl_size, activation='relu',
                kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1))
        self.h_glance_layer_sum = tf.keras.layers.Dense(g_size,
                kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1))
        self.h_location_layer_sum = tf.keras.layers.Dense(g_size,
                kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1))
        self.h_glance_concat_1 = tf.keras.layers.Dense(g_size, activation='relu',
                kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1))
        self.h_glance_concat_2 = tf.keras.layers.Dense(g_size, activation='relu',
                kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1))

    def reset_lists(self):
        self.eval_location_list = []
        self.location_x_list = []
        self.location_x_mean_list = []
        self.location_x_stddev_list = []
        self.location_a_list = []
        self.location_a_mean_list = []
        self.location_a_stddev_list = []
        self.glances_list = []
        self.first_glance = True

    def get_lists(self):
        return self.eval_location_list, self.location_list, self.location_mean_list, self.location_stddev_list, self.glances_list

    def call(self, inputs, output):
        glance = self.Haptic_Net(inputs, loc)
        # Location mean generated by initial hidden state of RNN
        mean_x = tensorflow.cond(self.random_locs,
                                 lambda: tensorflow.random_uniform((self.batch_size,1), minval=-1., maxval=1.),
                                 lambda: self.h_location_out_x(output)
        mean_a = tensorflow.cond(self.random_locs,
                                 lambda: tensorflow.random_uniform((self.batch_size,1), minval=-1., maxval=1.),
                                 lambda: tensorflow.nn.tanh(tensorflow.matmul(output_1, self.h_l_out_a)))
        std_x = tensorflow.cond(self.random_locs,
                                lambda: tensorflow.random_uniform((self.batch_size,1), minval=0., maxval=1.),
                                lambda: tensorflow.nn.sigmoid(tensorflow.matmul(output_1, self.h_l_std_out_x)))
        std_a = tensorflow.cond(self.random_locs,
                                lambda: tensorflow.random_uniform((self.batch_size,1), minval=0., maxval=1.),
                                lambda: tensorflow.nn.sigmoid(tensorflow.matmul(output_1, self.h_l_std_out_a)))
        loc_a = mean_a + tensorflow.random_normal(mean_a.get_shape(), 0, std_a)
        loc_x = mean_x + tensorflow.random_normal(mean_x.get_shape(), 0, std_x)

        # Prevent nan
        loc_a = tf.where(tf.math.is_nan(loc_a), tf.zeros_like(loc_a), loc_a)
        loc_x = tf.where(tf.math.is_nan(loc_x), tf.zeros_like(loc_x), loc_x)


        # Append stuff to lists
        self.location_x_mean_list.append(mean_x)
        self.location_x_stddev_list.append(std_x)
        self.location_x_list.append(loc_x)
        self.location_a_mean_list.append(mean_a)
        self.location_a_stddev_list.append(std_a)
        self.location_a_list.append(loc_a)

        return loc_x, loc_a, mean_x, mean_a, std_x, std_a

    def Haptic_Net(self, pressure, loc):
        """
        The 'Haptic Net' for combining the pressure
        information with the location of the sensor
        :param pressure: a pressure vector
        :param loc: a location
        :return: a feature vector
        """

        # Get glances
        glances = self.glanceSensor(location, inputs)
        # Append glances to list for tensorboard summary
        self.glances_list.append(glances[0])

        # Process glances
        glances = tf.reshape(glances, [self.batch_size, self.totalSensorBandwidth])
        hg = self.h_glance_layer(glances)

        # # Process locations
        hl = self.h_location_layer(location)

        # # Combine glances and locations
        concat = tensorflow.concat([self.h_glance_layer_sum(hg), self.h_location_layer_sum(hl)], axis=-1)
        g_1 = self.h_glance_concat_1(concat)
        g = self.h_glance_concat_1(g_1)
        return g

    def glanceSensor(self, normLoc, inputs):
        """
        Compute glances
        :param normLoc: Location for the next glances
        :return: glances
        """
        # Convert location [-1,1] into MNIST Coordinates:
        loc = tf.round(((normLoc + 1.) / 2.) * self.mnist_size)
        loc = tf.cast(loc, tf.int32)


        zooms = []

        # process each image individually
        for k in range(self.batch_size):
            imgZooms = []
            one_img = inputs[k,:,:,:]
            offset = self.sensorBandwidth* (self.pixel_scaling ** (self.depth-1))

            offset = tf.cast(offset, tf.int32)
            # pad image with zeros
            one_img = tf.image.pad_to_bounding_box(one_img, offset, offset, \
                                                   2*offset + self.mnist_size, 2*offset + self.mnist_size)

            # compute the different depth images
            for i in range(self.depth):

                # width/height of the next glance
                d = tf.cast(self.sensorBandwidth * (self.pixel_scaling ** i), tf.int32)
                r = d//2

                # get mean location
                loc_k = loc[k,:]
                adjusted_loc = offset + loc_k - r

                one_img2 = tf.reshape(one_img, (one_img.get_shape()[0], \
                                                 one_img.get_shape()[1]))

                # crop image to (d x d)
                zoom = tf.slice(one_img2, adjusted_loc, [d,d])
                if i > 0:
                    zoom = tf.reshape(zoom, (1, d, d, 1))
                    zoom = tf.image.resize(zoom, (self.sensorBandwidth, self.sensorBandwidth))
                    zoom = tf.reshape(zoom, (self.sensorBandwidth, self.sensorBandwidth))

                imgZooms.append(zoom)
            zooms.append(tf.stack(imgZooms))
        zooms = tf.stack(zooms)
        return zooms


class Baseline(tf.keras.Model):
    def __init__(self, units, batch_size):
        super(Baseline, self).__init__()
        self.batch_size = batch_size
        self.units = units

        self.input_placeholder = tf.keras.layers.InputLayer(input_shape=([batch_size, 256]))
        # baseline
        self.baseline_layer = tf.keras.layers.Dense(1, kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1))
    def call(self, outputs):

        # Use mean baseline of all glances
        b_pred = []
        for o in outputs:
            o = tf.reshape(tf.stop_gradient(o), (self.batch_size, self.units))
            i = self.input_placeholder(o)
            b_pred.append(tf.squeeze(self.baseline_layer(i)))
            b = tf.transpose(tf.stack(b_pred),perm=[1,0])
        return b


class RAM(tf.keras.Model):
    def __init__(self, PARAMETERS):
        super(RAM, self).__init__()

        # number of classes
        self.output_dim = PARAMETERS.OBJECT_NUM
        self.batch_size = 1
        self.real_batch_size = float(PARAMETERS.BATCH_SIZE)
        self.all_glances= PARAMETERS.GLANCES
        self.sensor_size = 256
        self.core_net = PARAMETERS.CORE_NET

        # Learning
        self.optimizer = PARAMETERS.OPTIMIZER
        self.momentum = PARAMETERS.MOMENTUM

        # Size of Hidden state
        self.hs_size = PARAMETERS.HIDDEN_STATE
        self.hn_size = PARAMETERS.HAPTIC_NET
        self.location_weight = PARAMETERS.LOCATION_WEIGHT

        self.inputs_placeholder = tf.keras.layers.InputLayer(input_shape=([batch_size, mnist_size, mnist_size, 1]))

        # Choose kind of memory layer
        if PARAMETERS.CORE_NET == "MLP":
            self.memory = tf.keras.layers.Dense(self.hs_size,
                activation='relu',
                kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1))
        elif PARAMETERS.CORE_NET == "LSTM":
            self.memory = tf.keras.layers.LSTMCell(self, activation='relu')
        else:
            import sys
            print("Wrong option for core network: {}".format(PARAMETERS.CORE_NET))
            sys.exit(0)

        # classification
        self.classification_layer = tf.keras.layers.Dense(10,
                activation=tf.nn.log_softmax,
                kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1))
        # used for attention
        self.attention = AttentionControl(PARAMETERS)

    def reset_attention(self):
        self.attention.reset_lists()

    def get_attention_lists(self):
        return self.attention.get_lists()

    def call(self, inputs):
        outputs = []
        output = tf.zeros((self.batch_size, self.units))
        hidden = [output, output]

        self.attention.reset_lists()
        if self.core_net == "LSTM":
            self.memory.reset_recurrent_dropout_mask()
            self.memory.reset_dropout_mask()

        input_layer = self.inputs_placeholder(inputs)
        for _ in range(self.glances):
            glance = self.attention(input_layer, output)
            if self.core_net == "LSTM":
                output, hidden = self.memory(glance, hidden)
            else: 
                output = self.memory(glance)
            outputs.append(output)
        # look at ONLY THE END of the sequence to predict label
        action_out = self.classification_layer(output)

        return glance, action_out, outputs

    def loss(self, correct_y, action_out, baseline):
        """
        Get classification and compute losses
        :param outputs: Sequence of hidden states of the RNN
        :return: accumulated loss, location policy loss, baseline loss, mean reward, predicted labels,
         gradient of hybrid loss, gradient of baseline loss
        """

        max_p_y = tf.argmax(action_out, axis=-1)
        actions_onehot = tf.one_hot(correct_y, 10)
        # reward per example
        R_batch = tf.cast(tf.equal(max_p_y, correct_y), tf.float32)
        R = tf.reshape(R_batch, (self.batch_size, 1))
        R = tf.stop_gradient(R)
        R = tf.tile(R, [1, self.glances])

        # mean reward
        # reward = tf.reduce_mean(R_batch)

        # REINFORCE algorithm for policy network loss
        # -------
        # Williams, Ronald J. "Simple statistical gradient-following
        # algorithms for connectionist reinforcement learning."
        # Machine learning 8.3-4 (1992): 229-256.
        # -------
        # characteristic eligibility taken from sec 6. p.237-239
        #
        # d ln(f(m,s,x))   (x - m)
        # -------------- = -------- with m = mean, x = sample, s = standard deviation
        #       d m          s**2
        #

        #Remove the summation of 2D Location while appending to list and evaluate the characteristic elegibility indiviually for each dimension

        baseline = tf.stop_gradient(baseline)
        double_baseline = []
        double_R= []
        for b in range(len(baseline)):
            double_baseline.append(baseline[b])
            double_baseline.append(baseline[b])
            double_R.append(R[b])
            double_R.append(R[b])
        double_baseline = tf.stack(double_baseline)
        double_R = tf.stack(double_R)

        loc = tf.reshape(tf.stack(self.attention.location_list),
                    shape=(self.batch_size*2,self.glances))
        mean_loc = tf.reshape(tf.stack(self.attention.location_mean_list),
                    shape=(self.batch_size*2,self.glances))
        std_loc = tf.reshape(tf.stack(self.attention.location_stddev_list),
                    shape=(self.batch_size*2,self.glances))

        Reinforce = (loc - mean_loc)/std_loc**2 * (double_R - double_baseline)
        Reinforce_std = (((loc - mean_loc)**2) - std_loc**2)/(std_loc**3) * (double_R - double_baseline)

        Reinforce = tf.reshape([tf.keras.backend.sum(tf.reduce_sum(Reinforce,
            -1)[i:i+2]) for i in range(0, self.batch_size*2, 2)],
            shape=(self.batch_size,))
        Reinforce_std = tf.reshape([tf.keras.backend.sum(tf.reduce_sum(Reinforce_std,
            -1)[i:i+2]) for i in range(0, self.batch_size*2, 2)],
            shape=(self.batch_size,))
        # print("locList: ", self.attention.location_list)
        # print("locStack: ", tf.reshape(tf.stack(self.attention.location_list),
        #             shape=(self.batch_size*2,self.glances)))

        # print("R: ", double_R)
        # print("bL ", double_baseline)
        # print(Reinforce_std)

        #######################################################################
        # Optimized for mean -> Also need to change appendance lists in attention layer

        # loc = tf.transpose(tf.stack(self.attention.location_list),perm=[1,0])
        # mean_loc = tf.transpose(tf.stack(self.attention.location_mean_list),perm=[1,0,])
        # std_loc = tf.transpose(tf.stack(self.attention.location_stddev_list),perm=[1,0,])


        # Reinforce = tf.reduce_mean((loc -
        #     mean_loc)/std_loc**2 * (R - baseline))
        # Reinforce_std = tf.reduce_mean((((loc -
        #     mean_loc)**2)-std_loc**2)/(std_loc**3) *
        #     (R - baseline))
        #######################################################################

        # balances the scale of the two gradient components
        ratio = self.location_weight

        # Action Loss
        J = tf.reduce_sum(action_out * actions_onehot,axis=1)

        # Hybrid Loss
        # Scale the learning rate for the REINFORCE part by tf.stop_gradient(std_loc)**2, as suggested in (Williams, 1992)
        #cost = - tf.reduce_mean(J + ratio * tf.reduce_mean(tf.stop_gradient(std_loc))**2* (Reinforce+Reinforce_std), axis=0)
        cost = - tf.reduce_mean(J + ratio * (Reinforce+Reinforce_std), axis=0)


        return cost, -Reinforce, -Reinforce_std, R
